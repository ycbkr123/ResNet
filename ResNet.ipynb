{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1UyuPwSrdEmyMqciJxu_L_ogB-D5VJ7Ha","authorship_tag":"ABX9TyOEaZ78xHB+9DZexGMPhTl2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["%cd '/content/drive/MyDrive/Colab Notebooks/CNNmodel/ResNet'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wm7sgPwvv7d7","executionInfo":{"status":"ok","timestamp":1666077342494,"user_tz":-540,"elapsed":487,"user":{"displayName":"지나가는사람","userId":"14104558034696293435"}},"outputId":"3fce1717-7dde-41f8-f5dc-007fe2efbada"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/CNNmodel/ResNet\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vYtgbNoduMpD"},"outputs":[],"source":["# 라이브러리 불러오기\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from skimage import io, transform\n","from tensorflow.keras import datasets, layers, models\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","import os\n","import warnings\n","from tqdm import tqdm\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["# ResNet 모델 불러오기\n","!git clone 'https://github.com/pytorch/vision.git'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtZ2s8jTwWZy","executionInfo":{"status":"ok","timestamp":1666077353407,"user_tz":-540,"elapsed":16,"user":{"displayName":"지나가는사람","userId":"14104558034696293435"}},"outputId":"20857421-6084-4bea-fca8-cde17439d086"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'vision' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/Colab Notebooks/CNNmodel/ResNet/vision'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fVsTtvIXxuPC","executionInfo":{"status":"ok","timestamp":1666077353407,"user_tz":-540,"elapsed":8,"user":{"displayName":"지나가는사람","userId":"14104558034696293435"}},"outputId":"446091fa-df93-437e-b128-77dbb6350171"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/CNNmodel/ResNet/vision\n"]}]},{"cell_type":"markdown","source":["# PyTorch ResNet 모델 구현"],"metadata":{"id":"fIhhuVmeo8NV"}},{"cell_type":"code","source":["# 모델 구현\n","import torch\n","import torch.nn as nn\n","from torch.hub import load_state_dict_from_url\n","\n","\n","__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n","           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n","           'wide_resnet50_2', 'wide_resnet101_2']\n","\n","\n","model_urls = {\n","    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n","    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n","    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n","    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n","    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n","    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n","    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n","    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n","    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n","}\n","\n","def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n","\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1, norm_layer=None):\n","        super(BasicBlock, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        if groups != 1 or base_width != 64:\n","            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n","        if dilation > 1:\n","            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n","        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = norm_layer(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = norm_layer(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1, norm_layer=None):\n","        super(Bottleneck, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        width = int(planes * (base_width / 64.)) * groups\n","        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv1x1(inplanes, width)\n","        self.bn1 = norm_layer(width)\n","        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n","        self.bn2 = norm_layer(width)\n","        self.conv3 = conv1x1(width, planes * self.expansion)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, num_classes=10, zero_init_residual=False,\n","                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n","                 norm_layer=None):\n","        super(ResNet, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        self._norm_layer = norm_layer\n","\n","        self.inplanes = 32\n","        self.dilation = 1\n","        if replace_stride_with_dilation is None:\n","            replace_stride_with_dilation = [False, False, False]\n","        if len(replace_stride_with_dilation) != 3:\n","            raise ValueError(\"replace_stride_with_dilation should be None \"\n","                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n","        self.groups = groups\n","        self.base_width = width_per_group\n","        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n","                               bias=False)\n","        self.bn1 = norm_layer(self.inplanes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n","                                       dilate=replace_stride_with_dilation[0])\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n","                                       dilate=replace_stride_with_dilation[1])\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n","                                       dilate=replace_stride_with_dilation[2])\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        # Zero-initialize the last BN in each residual branch,\n","        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n","        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, Bottleneck):\n","                    nn.init.constant_(m.bn3.weight, 0)\n","                elif isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n","        norm_layer = self._norm_layer\n","        downsample = None\n","        previous_dilation = self.dilation\n","        if dilate:\n","            self.dilation *= stride\n","            stride = 1\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes * block.expansion, stride),\n","                norm_layer(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n","                            self.base_width, previous_dilation, norm_layer))\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, groups=self.groups,\n","                                base_width=self.base_width, dilation=self.dilation,\n","                                norm_layer=norm_layer))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _forward_impl(self, x):\n","        # See note [TorchScript super()]\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","    def forward(self, x):\n","        return self._forward_impl(x)\n","\n","\n","def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n","    model = ResNet(block, layers, **kwargs)\n","    if pretrained:\n","        state_dict = load_state_dict_from_url(model_urls[arch],\n","                                              progress=progress)\n","        model.load_state_dict(state_dict)\n","    return model\n","\n","\n","def resnet18(pretrained=False, progress=True, **kwargs):\n","    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n","                   **kwargs)\n","\n","\n","def resnet34(pretrained=False, progress=True, **kwargs):\n","    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,\n","                   **kwargs)\n","\n","\n","def resnet50(pretrained=False, progress=True, **kwargs):\n","    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n","                   **kwargs)\n","\n","\n","def resnet101(pretrained=False, progress=True, **kwargs):\n","    return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress,\n","                   **kwargs)\n","\n","\n","def resnet152(pretrained=False, progress=True, **kwargs):\n","    return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress,\n","                   **kwargs)\n","\n","\n","def resnext50_32x4d(pretrained=False, progress=True, **kwargs):\n","    kwargs['groups'] = 32\n","    kwargs['width_per_group'] = 4\n","    return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3],\n","                   pretrained, progress, **kwargs)\n","\n","\n","def resnext101_32x8d(pretrained=False, progress=True, **kwargs):\n","    kwargs['groups'] = 32\n","    kwargs['width_per_group'] = 8\n","    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\n","                   pretrained, progress, **kwargs)\n","\n","\n","def wide_resnet50_2(pretrained=False, progress=True, **kwargs):\n","    kwargs['width_per_group'] = 64 * 2\n","    return _resnet('wide_resnet50_2', Bottleneck, [3, 4, 6, 3],\n","                   pretrained, progress, **kwargs)\n","\n","\n","def wide_resnet101_2(pretrained=False, progress=True, **kwargs):\n","    kwargs['width_per_group'] = 64 * 2\n","    return _resnet('wide_resnet101_2', Bottleneck, [3, 4, 23, 3],\n","                   pretrained, progress, **kwargs)"],"metadata":{"id":"Nj407KfjBUNg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# trainset, testset, dataloader 생성\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","\n","# 모델 생성\n","model = resnet101()\n","\n","# 정규화 지정\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","# train, test loader 만들기\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                        download=True, transform=transform)\n","trainloader = DataLoader(trainset, batch_size=256,\n","                                          shuffle=True, num_workers=2)\n","testloader = DataLoader(testset, batch_size=256,\n","                                          shuffle=True, num_workers=2)\n","\n","model.eval()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params = model.parameters(), lr = 0.0001)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ogccI9X5a49","executionInfo":{"status":"ok","timestamp":1666077365699,"user_tz":-540,"elapsed":5580,"user":{"displayName":"지나가는사람","userId":"14104558034696293435"}},"outputId":"f49932a3-5a41-4d01-e03a-4a7cf1c4af86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["# Trainer (학습)\n","for epoch in tqdm(range(2)):  # 데이터셋을 수차례 반복합니다.\n","    running_loss = 0.0\n","    for i, data in tqdm(enumerate(trainloader, 0)):\n","        # [inputs, labels]의 목록인 data로부터 입력을 받기\n","        inputs, labels = data\n","\n","        # 변화도(Gradient) 매개변수를 0으로 만들고\n","        optimizer.zero_grad()\n","\n","        # 순전파 + 역전파 + 최적화를 한 후\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # 통계를 출력합니다.\n","        running_loss += loss.item()\n","        if i % 2000 == 1999:    # print every 2000 mini-batches\n","            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}') # 2000:3f\n","            running_loss = 0.0\n","\n","print('Finished Training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AwhCV08fwvq3","executionInfo":{"status":"ok","timestamp":1666081447045,"user_tz":-540,"elapsed":4079226,"user":{"displayName":"지나가는사람","userId":"14104558034696293435"}},"outputId":"15433c02-87c4-4672-9120-0669447a07fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/2 [00:00<?, ?it/s]\n","0it [00:00, ?it/s]\u001b[A\n","1it [00:16, 16.94s/it]\u001b[A\n","2it [00:28, 14.06s/it]\u001b[A\n","3it [00:39, 12.42s/it]\u001b[A\n","4it [00:49, 11.63s/it]\u001b[A\n","5it [01:00, 11.20s/it]\u001b[A\n","6it [01:10, 10.95s/it]\u001b[A\n","7it [01:21, 10.81s/it]\u001b[A\n","8it [01:31, 10.67s/it]\u001b[A\n","9it [01:42, 10.63s/it]\u001b[A\n","10it [01:52, 10.58s/it]\u001b[A\n","11it [02:03, 10.61s/it]\u001b[A\n","12it [02:13, 10.57s/it]\u001b[A\n","13it [02:24, 10.52s/it]\u001b[A\n","14it [02:34, 10.49s/it]\u001b[A\n","15it [02:45, 10.47s/it]\u001b[A\n","16it [02:55, 10.43s/it]\u001b[A\n","17it [03:05, 10.43s/it]\u001b[A\n","18it [03:16, 10.44s/it]\u001b[A\n","19it [03:26, 10.45s/it]\u001b[A\n","20it [03:37, 10.43s/it]\u001b[A\n","21it [03:47, 10.43s/it]\u001b[A\n","22it [03:59, 10.81s/it]\u001b[A\n","23it [04:09, 10.68s/it]\u001b[A\n","24it [04:20, 10.60s/it]\u001b[A\n","25it [04:30, 10.53s/it]\u001b[A\n","26it [04:40, 10.48s/it]\u001b[A\n","27it [04:51, 10.46s/it]\u001b[A\n","28it [05:01, 10.42s/it]\u001b[A\n","29it [05:12, 10.44s/it]\u001b[A\n","30it [05:22, 10.41s/it]\u001b[A\n","31it [05:32, 10.39s/it]\u001b[A\n","32it [05:43, 10.39s/it]\u001b[A\n","33it [05:53, 10.38s/it]\u001b[A\n","34it [06:03, 10.38s/it]\u001b[A\n","35it [06:14, 10.38s/it]\u001b[A\n","36it [06:24, 10.37s/it]\u001b[A\n","37it [06:34, 10.38s/it]\u001b[A\n","38it [06:45, 10.36s/it]\u001b[A\n","39it [06:55, 10.38s/it]\u001b[A\n","40it [07:06, 10.38s/it]\u001b[A\n","41it [07:16, 10.40s/it]\u001b[A\n","42it [07:27, 10.53s/it]\u001b[A\n","43it [07:38, 10.82s/it]\u001b[A\n","44it [07:49, 10.70s/it]\u001b[A\n","45it [07:59, 10.61s/it]\u001b[A\n","46it [08:09, 10.52s/it]\u001b[A\n","47it [08:20, 10.49s/it]\u001b[A\n","48it [08:30, 10.44s/it]\u001b[A\n","49it [08:42, 10.76s/it]\u001b[A\n","50it [08:52, 10.63s/it]\u001b[A\n","51it [09:03, 10.61s/it]\u001b[A\n","52it [09:13, 10.53s/it]\u001b[A\n","53it [09:23, 10.52s/it]\u001b[A\n","54it [09:34, 10.48s/it]\u001b[A\n","55it [09:44, 10.46s/it]\u001b[A\n","56it [09:55, 10.43s/it]\u001b[A\n","57it [10:05, 10.43s/it]\u001b[A\n","58it [10:15, 10.40s/it]\u001b[A\n","59it [10:26, 10.39s/it]\u001b[A\n","60it [10:36, 10.37s/it]\u001b[A\n","61it [10:46, 10.37s/it]\u001b[A\n","62it [10:57, 10.37s/it]\u001b[A\n","63it [11:09, 10.85s/it]\u001b[A\n","64it [11:19, 10.72s/it]\u001b[A\n","65it [11:29, 10.60s/it]\u001b[A\n","66it [11:40, 10.54s/it]\u001b[A\n","67it [11:50, 10.51s/it]\u001b[A\n","68it [12:01, 10.47s/it]\u001b[A\n","69it [12:11, 10.48s/it]\u001b[A\n","70it [12:22, 10.44s/it]\u001b[A\n","71it [12:32, 10.43s/it]\u001b[A\n","72it [12:42, 10.41s/it]\u001b[A\n","73it [12:53, 10.40s/it]\u001b[A\n","74it [13:03, 10.40s/it]\u001b[A\n","75it [13:14, 10.40s/it]\u001b[A\n","76it [13:24, 10.39s/it]\u001b[A\n","77it [13:34, 10.40s/it]\u001b[A\n","78it [13:45, 10.40s/it]\u001b[A\n","79it [13:55, 10.41s/it]\u001b[A\n","80it [14:06, 10.42s/it]\u001b[A\n","81it [14:16, 10.43s/it]\u001b[A\n","82it [14:26, 10.44s/it]\u001b[A\n","83it [14:37, 10.43s/it]\u001b[A\n","84it [14:49, 10.92s/it]\u001b[A\n","85it [14:59, 10.79s/it]\u001b[A\n","86it [15:10, 10.66s/it]\u001b[A\n","87it [15:20, 10.58s/it]\u001b[A\n","88it [15:31, 10.52s/it]\u001b[A\n","89it [15:41, 10.51s/it]\u001b[A\n","90it [15:51, 10.47s/it]\u001b[A\n","91it [16:02, 10.50s/it]\u001b[A\n","92it [16:12, 10.46s/it]\u001b[A\n","93it [16:23, 10.46s/it]\u001b[A\n","94it [16:33, 10.45s/it]\u001b[A\n","95it [16:44, 10.46s/it]\u001b[A\n","96it [16:54, 10.43s/it]\u001b[A\n","97it [17:04, 10.42s/it]\u001b[A\n","98it [17:15, 10.39s/it]\u001b[A\n","99it [17:25, 10.41s/it]\u001b[A\n","100it [17:36, 10.40s/it]\u001b[A\n","101it [17:46, 10.40s/it]\u001b[A\n","102it [17:56, 10.41s/it]\u001b[A\n","103it [18:07, 10.41s/it]\u001b[A\n","104it [18:17, 10.40s/it]\u001b[A\n","105it [18:29, 10.86s/it]\u001b[A\n","106it [18:40, 10.70s/it]\u001b[A\n","107it [18:50, 10.61s/it]\u001b[A\n","108it [19:00, 10.55s/it]\u001b[A\n","109it [19:11, 10.49s/it]\u001b[A\n","110it [19:21, 10.42s/it]\u001b[A\n","111it [19:31, 10.42s/it]\u001b[A\n","112it [19:42, 10.39s/it]\u001b[A\n","113it [19:52, 10.40s/it]\u001b[A\n","114it [20:03, 10.41s/it]\u001b[A\n","115it [20:13, 10.41s/it]\u001b[A\n","116it [20:23, 10.42s/it]\u001b[A\n","117it [20:34, 10.41s/it]\u001b[A\n","118it [20:44, 10.38s/it]\u001b[A\n","119it [20:54, 10.38s/it]\u001b[A\n","120it [21:05, 10.37s/it]\u001b[A\n","121it [21:15, 10.39s/it]\u001b[A\n","122it [21:26, 10.40s/it]\u001b[A\n","123it [21:36, 10.41s/it]\u001b[A\n","124it [21:47, 10.42s/it]\u001b[A\n","125it [21:57, 10.42s/it]\u001b[A\n","126it [22:09, 10.86s/it]\u001b[A\n","127it [22:19, 10.71s/it]\u001b[A\n","128it [22:30, 10.59s/it]\u001b[A\n","129it [22:40, 10.50s/it]\u001b[A\n","130it [22:50, 10.43s/it]\u001b[A\n","131it [23:00, 10.42s/it]\u001b[A\n","132it [23:11, 10.39s/it]\u001b[A\n","133it [23:21, 10.37s/it]\u001b[A\n","134it [23:31, 10.37s/it]\u001b[A\n","135it [23:42, 10.36s/it]\u001b[A\n","136it [23:52, 10.35s/it]\u001b[A\n","137it [24:03, 10.40s/it]\u001b[A\n","138it [24:13, 10.38s/it]\u001b[A\n","139it [24:23, 10.37s/it]\u001b[A\n","140it [24:34, 10.35s/it]\u001b[A\n","141it [24:44, 10.36s/it]\u001b[A\n","142it [24:54, 10.38s/it]\u001b[A\n","143it [25:05, 10.41s/it]\u001b[A\n","144it [25:15, 10.39s/it]\u001b[A\n","145it [25:26, 10.40s/it]\u001b[A\n","146it [25:36, 10.43s/it]\u001b[A\n","147it [25:48, 10.95s/it]\u001b[A\n","148it [25:59, 10.81s/it]\u001b[A\n","149it [26:09, 10.75s/it]\u001b[A\n","150it [26:20, 10.64s/it]\u001b[A\n","151it [26:30, 10.58s/it]\u001b[A\n","152it [26:41, 10.52s/it]\u001b[A\n","153it [26:51, 10.49s/it]\u001b[A\n","154it [27:02, 10.49s/it]\u001b[A\n","155it [27:12, 10.48s/it]\u001b[A\n","156it [27:22, 10.44s/it]\u001b[A\n","157it [27:33, 10.42s/it]\u001b[A\n","158it [27:43, 10.39s/it]\u001b[A\n","159it [27:53, 10.38s/it]\u001b[A\n","160it [28:04, 10.39s/it]\u001b[A\n","161it [28:14, 10.39s/it]\u001b[A\n","162it [28:25, 10.38s/it]\u001b[A\n","163it [28:35, 10.38s/it]\u001b[A\n","164it [28:45, 10.40s/it]\u001b[A\n","165it [28:56, 10.50s/it]\u001b[A\n","166it [29:06, 10.45s/it]\u001b[A\n","167it [29:17, 10.44s/it]\u001b[A\n","168it [29:29, 10.90s/it]\u001b[A\n","169it [29:39, 10.75s/it]\u001b[A\n","170it [29:50, 10.63s/it]\u001b[A\n","171it [30:00, 10.58s/it]\u001b[A\n","172it [30:10, 10.51s/it]\u001b[A\n","173it [30:21, 10.47s/it]\u001b[A\n","174it [30:31, 10.42s/it]\u001b[A\n","175it [30:42, 10.42s/it]\u001b[A\n","176it [30:52, 10.42s/it]\u001b[A\n","177it [31:02, 10.44s/it]\u001b[A\n","178it [31:13, 10.43s/it]\u001b[A\n","179it [31:23, 10.43s/it]\u001b[A\n","180it [31:34, 10.45s/it]\u001b[A\n","181it [31:44, 10.45s/it]\u001b[A\n","182it [31:55, 10.45s/it]\u001b[A\n","183it [32:05, 10.46s/it]\u001b[A\n","184it [32:16, 10.43s/it]\u001b[A\n","185it [32:26, 10.41s/it]\u001b[A\n","186it [32:36, 10.39s/it]\u001b[A\n","187it [32:47, 10.40s/it]\u001b[A\n","188it [32:57, 10.38s/it]\u001b[A\n","189it [33:08, 10.65s/it]\u001b[A\n","190it [33:19, 10.79s/it]\u001b[A\n","191it [33:30, 10.66s/it]\u001b[A\n","192it [33:40, 10.56s/it]\u001b[A\n","193it [33:50, 10.50s/it]\u001b[A\n","194it [34:01, 10.44s/it]\u001b[A\n","195it [34:11, 10.42s/it]\u001b[A\n","196it [34:15, 10.49s/it]\n"," 50%|█████     | 1/2 [34:15<34:15, 2055.43s/it]\n","0it [00:00, ?it/s]\u001b[A\n","1it [00:12, 12.82s/it]\u001b[A\n","2it [00:23, 11.29s/it]\u001b[A\n","3it [00:33, 10.82s/it]\u001b[A\n","4it [00:43, 10.58s/it]\u001b[A\n","5it [00:53, 10.47s/it]\u001b[A\n","6it [01:03, 10.38s/it]\u001b[A\n","7it [01:14, 10.34s/it]\u001b[A\n","8it [01:24, 10.31s/it]\u001b[A\n","9it [01:34, 10.29s/it]\u001b[A\n","10it [01:45, 10.29s/it]\u001b[A\n","11it [01:55, 10.32s/it]\u001b[A\n","12it [02:05, 10.29s/it]\u001b[A\n","13it [02:15, 10.30s/it]\u001b[A\n","14it [02:26, 10.29s/it]\u001b[A\n","15it [02:38, 10.80s/it]\u001b[A\n","16it [02:48, 10.66s/it]\u001b[A\n","17it [02:58, 10.55s/it]\u001b[A\n","18it [03:09, 10.44s/it]\u001b[A\n","19it [03:19, 10.40s/it]\u001b[A\n","20it [03:29, 10.35s/it]\u001b[A\n","21it [03:39, 10.32s/it]\u001b[A\n","22it [03:50, 10.30s/it]\u001b[A\n","23it [04:00, 10.29s/it]\u001b[A\n","24it [04:10, 10.27s/it]\u001b[A\n","25it [04:20, 10.26s/it]\u001b[A\n","26it [04:30, 10.24s/it]\u001b[A\n","27it [04:41, 10.25s/it]\u001b[A\n","28it [04:51, 10.25s/it]\u001b[A\n","29it [05:01, 10.23s/it]\u001b[A\n","30it [05:11, 10.23s/it]\u001b[A\n","31it [05:22, 10.23s/it]\u001b[A\n","32it [05:32, 10.25s/it]\u001b[A\n","33it [05:42, 10.25s/it]\u001b[A\n","34it [05:53, 10.29s/it]\u001b[A\n","35it [06:03, 10.28s/it]\u001b[A\n","36it [06:13, 10.29s/it]\u001b[A\n","37it [06:28, 11.73s/it]\u001b[A\n","38it [06:38, 11.28s/it]\u001b[A\n","39it [06:49, 10.98s/it]\u001b[A\n","40it [06:59, 10.76s/it]\u001b[A\n","41it [07:09, 10.62s/it]\u001b[A\n","42it [07:20, 10.53s/it]\u001b[A\n","43it [07:30, 10.48s/it]\u001b[A\n","44it [07:40, 10.43s/it]\u001b[A\n","45it [07:51, 10.41s/it]\u001b[A\n","46it [08:01, 10.37s/it]\u001b[A\n","47it [08:11, 10.32s/it]\u001b[A\n","48it [08:21, 10.28s/it]\u001b[A\n","49it [08:32, 10.27s/it]\u001b[A\n","50it [08:42, 10.24s/it]\u001b[A\n","51it [08:52, 10.25s/it]\u001b[A\n","52it [09:02, 10.25s/it]\u001b[A\n","53it [09:12, 10.25s/it]\u001b[A\n","54it [09:23, 10.25s/it]\u001b[A\n","55it [09:33, 10.25s/it]\u001b[A\n","56it [09:43, 10.29s/it]\u001b[A\n","57it [09:54, 10.27s/it]\u001b[A\n","58it [10:05, 10.67s/it]\u001b[A\n","59it [10:15, 10.55s/it]\u001b[A\n","60it [10:26, 10.45s/it]\u001b[A\n","61it [10:36, 10.37s/it]\u001b[A\n","62it [10:46, 10.36s/it]\u001b[A\n","63it [10:56, 10.33s/it]\u001b[A\n","64it [11:07, 10.31s/it]\u001b[A\n","65it [11:17, 10.29s/it]\u001b[A\n","66it [11:27, 10.29s/it]\u001b[A\n","67it [11:38, 10.29s/it]\u001b[A\n","68it [11:48, 10.31s/it]\u001b[A\n","69it [11:58, 10.31s/it]\u001b[A\n","70it [12:08, 10.31s/it]\u001b[A\n","71it [12:19, 10.30s/it]\u001b[A\n","72it [12:29, 10.30s/it]\u001b[A\n","73it [12:39, 10.30s/it]\u001b[A\n","74it [12:50, 10.29s/it]\u001b[A\n","75it [13:00, 10.28s/it]\u001b[A\n","76it [13:10, 10.26s/it]\u001b[A\n","77it [13:20, 10.25s/it]\u001b[A\n","78it [13:31, 10.26s/it]\u001b[A\n","79it [13:43, 10.76s/it]\u001b[A\n","80it [13:53, 10.63s/it]\u001b[A\n","81it [14:03, 10.51s/it]\u001b[A\n","82it [14:13, 10.43s/it]\u001b[A\n","83it [14:24, 10.37s/it]\u001b[A\n","84it [14:34, 10.33s/it]\u001b[A\n","85it [14:44, 10.30s/it]\u001b[A\n","86it [14:54, 10.28s/it]\u001b[A\n","87it [15:05, 10.26s/it]\u001b[A\n","88it [15:15, 10.25s/it]\u001b[A\n","89it [15:25, 10.24s/it]\u001b[A\n","90it [15:35, 10.25s/it]\u001b[A\n","91it [15:46, 10.27s/it]\u001b[A\n","92it [15:56, 10.26s/it]\u001b[A\n","93it [16:06, 10.27s/it]\u001b[A\n","94it [16:16, 10.26s/it]\u001b[A\n","95it [16:27, 10.26s/it]\u001b[A\n","96it [16:37, 10.26s/it]\u001b[A\n","97it [16:47, 10.27s/it]\u001b[A\n","98it [16:57, 10.29s/it]\u001b[A\n","99it [17:08, 10.28s/it]\u001b[A\n","100it [17:19, 10.64s/it]\u001b[A\n","101it [17:30, 10.69s/it]\u001b[A\n","102it [17:40, 10.59s/it]\u001b[A\n","103it [17:51, 10.51s/it]\u001b[A\n","104it [18:01, 10.46s/it]\u001b[A\n","105it [18:11, 10.37s/it]\u001b[A\n","106it [18:21, 10.32s/it]\u001b[A\n","107it [18:32, 10.28s/it]\u001b[A\n","108it [18:42, 10.32s/it]\u001b[A\n","109it [18:52, 10.30s/it]\u001b[A\n","110it [19:02, 10.27s/it]\u001b[A\n","111it [19:13, 10.24s/it]\u001b[A\n","112it [19:23, 10.23s/it]\u001b[A\n","113it [19:33, 10.24s/it]\u001b[A\n","114it [19:43, 10.26s/it]\u001b[A\n","115it [19:54, 10.24s/it]\u001b[A\n","116it [20:04, 10.24s/it]\u001b[A\n","117it [20:14, 10.21s/it]\u001b[A\n","118it [20:24, 10.23s/it]\u001b[A\n","119it [20:34, 10.21s/it]\u001b[A\n","120it [20:45, 10.21s/it]\u001b[A\n","121it [20:55, 10.24s/it]\u001b[A\n","122it [21:06, 10.65s/it]\u001b[A\n","123it [21:17, 10.52s/it]\u001b[A\n","124it [21:27, 10.46s/it]\u001b[A\n","125it [21:37, 10.38s/it]\u001b[A\n","126it [21:48, 10.36s/it]\u001b[A\n","127it [21:58, 10.33s/it]\u001b[A\n","128it [22:08, 10.31s/it]\u001b[A\n","129it [22:18, 10.30s/it]\u001b[A\n","130it [22:29, 10.29s/it]\u001b[A\n","131it [22:39, 10.45s/it]\u001b[A\n","132it [22:50, 10.40s/it]\u001b[A\n","133it [23:00, 10.35s/it]\u001b[A\n","134it [23:10, 10.31s/it]\u001b[A\n","135it [23:20, 10.27s/it]\u001b[A\n","136it [23:31, 10.24s/it]\u001b[A\n","137it [23:41, 10.26s/it]\u001b[A\n","138it [23:51, 10.24s/it]\u001b[A\n","139it [24:01, 10.26s/it]\u001b[A\n","140it [24:11, 10.23s/it]\u001b[A\n","141it [24:22, 10.23s/it]\u001b[A\n","142it [24:32, 10.22s/it]\u001b[A\n","143it [24:44, 10.67s/it]\u001b[A\n","144it [24:54, 10.53s/it]\u001b[A\n","145it [25:04, 10.45s/it]\u001b[A\n","146it [25:14, 10.37s/it]\u001b[A\n","147it [25:25, 10.35s/it]\u001b[A\n","148it [25:35, 10.30s/it]\u001b[A\n","149it [25:45, 10.31s/it]\u001b[A\n","150it [25:55, 10.29s/it]\u001b[A\n","151it [26:06, 10.29s/it]\u001b[A\n","152it [26:16, 10.30s/it]\u001b[A\n","153it [26:26, 10.30s/it]\u001b[A\n","154it [26:36, 10.28s/it]\u001b[A\n","155it [26:47, 10.34s/it]\u001b[A\n","156it [26:57, 10.32s/it]\u001b[A\n","157it [27:07, 10.30s/it]\u001b[A\n","158it [27:18, 10.27s/it]\u001b[A\n","159it [27:28, 10.27s/it]\u001b[A\n","160it [27:38, 10.26s/it]\u001b[A\n","161it [27:49, 10.27s/it]\u001b[A\n","162it [27:59, 10.24s/it]\u001b[A\n","163it [28:09, 10.23s/it]\u001b[A\n","164it [28:21, 10.70s/it]\u001b[A\n","165it [28:31, 10.58s/it]\u001b[A\n","166it [28:41, 10.46s/it]\u001b[A\n","167it [28:51, 10.40s/it]\u001b[A\n","168it [29:02, 10.36s/it]\u001b[A\n","169it [29:12, 10.31s/it]\u001b[A\n","170it [29:22, 10.27s/it]\u001b[A\n","171it [29:32, 10.27s/it]\u001b[A\n","172it [29:43, 10.25s/it]\u001b[A\n","173it [29:53, 10.24s/it]\u001b[A\n","174it [30:03, 10.21s/it]\u001b[A\n","175it [30:13, 10.20s/it]\u001b[A\n","176it [30:23, 10.18s/it]\u001b[A\n","177it [30:33, 10.18s/it]\u001b[A\n","178it [30:44, 10.24s/it]\u001b[A\n","179it [30:54, 10.24s/it]\u001b[A\n","180it [31:04, 10.22s/it]\u001b[A\n","181it [31:14, 10.21s/it]\u001b[A\n","182it [31:25, 10.22s/it]\u001b[A\n","183it [31:35, 10.23s/it]\u001b[A\n","184it [31:45, 10.23s/it]\u001b[A\n","185it [31:56, 10.47s/it]\u001b[A\n","186it [32:07, 10.69s/it]\u001b[A\n","187it [32:18, 10.57s/it]\u001b[A\n","188it [32:28, 10.46s/it]\u001b[A\n","189it [32:38, 10.40s/it]\u001b[A\n","190it [32:48, 10.35s/it]\u001b[A\n","191it [32:59, 10.32s/it]\u001b[A\n","192it [33:09, 10.30s/it]\u001b[A\n","193it [33:19, 10.28s/it]\u001b[A\n","194it [33:29, 10.25s/it]\u001b[A\n","195it [33:40, 10.29s/it]\u001b[A\n","196it [33:43, 10.33s/it]\n","100%|██████████| 2/2 [1:07:59<00:00, 2039.67s/it]"]},{"output_type":"stream","name":"stdout","text":["Finished Training\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"metadata":{"id":"LlpO8cW0cLKm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. trainset 생성기\n","class CustomDataset(Dataset):\n","    def __init__(self, csv_file, root_dir, transform=None):\n","        self.cifar10_frame = pd.read_csv(csv_file)\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.cifar10_frame)\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","            img_name = os.path.join(self.root_dir, self.cifar10_frame.iloc[idx, 0])\n","            image = io.imread(img_name)\n","            cifar10 = self.cifar10_frame.iloc[idx, 1:]\n","            cifar10 = np.array([cifar10])\n","            cifar10 = cifar10.astype('float').reshape(-1, 2)\n","            sample = {'image': image, 'cifar10': cifar10}\n","\n","            if self.transform:\n","                sample = self.transform(sample)\n","\n","            return sample"],"metadata":{"id":"3-jgiTu4ckI-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#모델 저장하기\n","PATH = './cifar_model.pth'\n","torch.save(model.state_dict(), PATH)\n","\n","dataiter = iter(testloader)\n","images, labels = dataiter.next()"],"metadata":{"id":"fNn6wf2fb1OX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 불러오기\n","model = resnet101()\n","model.load_state_dict(torch.load(PATH)) #위에서 정의한 PATH"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h4xzyiM8b1ue","executionInfo":{"status":"ok","timestamp":1666081482646,"user_tz":-540,"elapsed":2991,"user":{"displayName":"지나가는사람","userId":"14104558034696293435"}},"outputId":"febef0a3-3bf9-4c10-a249-9a028ffdc5de"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["dataiter = iter(testloader)\n","images, labels = dataiter.next()"],"metadata":{"id":"1Jm_r6deb3Zx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#전체 데이터 셋을 적용한 정확도\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in tqdm(testloader):\n","        images, labels = data\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jafsZ1s5b4yl","executionInfo":{"status":"ok","timestamp":1666081629946,"user_tz":-540,"elapsed":134552,"user":{"displayName":"지나가는사람","userId":"14104558034696293435"}},"outputId":"6d283970-5d63-4999-89cf-72482150848a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 40/40 [02:13<00:00,  3.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 10 %\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# 각 데이터 셋 적용한 정확도\n","class_correct = list(0. for i in range(10))\n","class_total = list(0. for i in range(10))\n","with torch.no_grad():\n","    for data in tqdm(testloader):\n","        images, labels = data\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        c = (predicted == labels).squeeze()\n","        for i in range(4):\n","            label = labels[i]\n","            class_correct[label] += c[i].item()\n","            class_total[label] += 1\n","\n","\n","for i in tqdm(range(10)):\n","    print('Accuracy of %5s : %2d %%' % (\n","        classes[i], 100 * class_correct[i] / class_total[i]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fwQtrw1Ub64t","executionInfo":{"status":"ok","timestamp":1666072366401,"user_tz":-540,"elapsed":30212,"user":{"displayName":"지나가는사람","userId":"14104558034696293435"}},"outputId":"fd956a34-ee1f-44ce-b14c-eb843472f57a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n","100%|██████████| 10/10 [00:00<00:00, 20340.95it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy of plane : 35 %\n","Accuracy of   car : 66 %\n","Accuracy of  bird :  6 %\n","Accuracy of   cat : 10 %\n","Accuracy of  deer :  0 %\n","Accuracy of   dog : 15 %\n","Accuracy of  frog : 33 %\n","Accuracy of horse : 46 %\n","Accuracy of  ship : 15 %\n","Accuracy of truck : 36 %\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["# Tensorflow로 구현한 ResNet 모델"],"metadata":{"id":"MLzy59f1poHC"}},{"cell_type":"code","source":["# 라이브러리 불러오기\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from skimage import io, transform\n","from tensorflow.keras import datasets, layers, models\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","import os\n","import warnings\n","from tqdm import tqdm\n","from keras.datasets import cifar10\n","warnings.filterwarnings('ignore')\n","\n","(train_input, train_target), (test_input, test_target) = cifar10.load_data()"],"metadata":{"id":"cCQV6ZlEq-sa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tensorflow에서 제공하는 ResNet50모델 훈련\n","from keras.applications.resnet import ResNet50\n","from keras.datasets import cifar10\n","\n","(train_input, train_target), (test_input, test_target) = cifar10.load_data()\n","model = ResNet50(include_top=True, weights=None, input_shape=(32, 32, 3), pooling=max, classes=10)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n","history = model.fit(train_input, train_target, epochs=50,\n","                    validation_data=(test_input, test_target))"],"metadata":{"id":"_Vqp09WG-myT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ResNet Block 생성\n","# is_50 : True --> resnet_50\n","# is_plain :True --> no skip connection\n","def build_resnet_block(input_layer, num_cnn=3, channel=64, block_num=1,is_50 = False,is_plain = False):\n","    # 입력 레이어\n","    x = input_layer\n","    if not is_50:\n","    # CNN 레이어\n","        for cnn_num in range(num_cnn):\n","            identity = x\n","            x = keras.layers.Conv2D(\n","                filters=channel,\n","                kernel_size=(3,3),\n","                activation='relu',\n","                kernel_initializer='he_normal',\n","                padding='same',\n","                name=f'block{block_num}_conv{cnn_num}'\n","            )(x)\n","            x = keras.layers.BatchNormalization()(x)\n","            x = keras.layers.Conv2D(\n","                filters=channel,\n","                kernel_size=(3,3),\n","                activation='relu',\n","                kernel_initializer='he_normal',\n","                padding='same',\n","                name=f'block{block_num}_1_conv{cnn_num}'\n","            )(x)\n","            if not is_plain:\n","                identity_channel = identity.shape.as_list()[-1]\n","\n","                if identity_channel != channel:\n","                    identity = keras.layers.Conv2D(channel, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(identity)\n","                # skip connection\n","                x = keras.layers.Add()([x,identity])\n","            else:\n","                pass\n","    else :\n","        identity = x\n","        x = keras.layers.Conv2D(\n","            filters=channel,\n","            kernel_size=(1,1),\n","            activation='relu',\n","            kernel_initializer='he_normal',\n","            padding='same',\n","            name=f'block{block_num}_conv{cnn_num}'\n","        )(x)\n","        x = keras.layers.BatchNormalization()(x)\n","        x = keras.layers.Conv2D(\n","            filters=channel,\n","            kernel_size=(3,3),\n","            activation='relu',\n","            kernel_initializer='he_normal',\n","            padding='same',\n","            name=f'block{block_num}_1_conv{cnn_num}'\n","        )(x)\n","        x = keras.layers.Conv2D(\n","            filters=channel * 4,\n","            kernel_size=(1,1),\n","            activation='relu',\n","            kernel_initializer='he_normal',\n","            padding='same',\n","            name=f'block{block_num}_2_conv{cnn_num}'\n","        )(x)\n","        if not is_plain:\n","            identity_channel = identity.shape.as_list()[-1]\n","\n","            if identity_channel != channel:\n","                identity = keras.layers.Conv2D(channel, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(identity)\n","            # skip connection\n","            x = keras.layers.Add()([x,identity])\n","        else:\n","            pass\n","    #     Max Pooling 레이어\n","    # 마지막 블록 뒤에는 pooling을 하지 않음\n","    if identity.shape[1] != 1:\n","        x = keras.layers.MaxPooling2D(\n","            pool_size=(2, 2),\n","            strides=2,\n","            name=f'block{block_num}_pooling'\n","        )(x)\n","\n","    return x"],"metadata":{"id":"5IqbV-clqbMC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ResNet Builder\n","def build_resnet(input_shape=(32,32,3),\n","              num_cnn_list=[3,4,6,3],\n","              channel_list=[64,128,256,512],\n","              num_classes=10,is_50 = False, is_plain = False):\n","\n","    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\n","    if is_50:\n","        num_cnn_list = [3,4,6,3]\n","        channel_list = [64,128,256,512]\n","        num_classes = 10\n","\n","    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n","    output = input_layer\n","    #conv1층\n","    output = keras.layers.Conv2D(filters=64,\n","                       kernel_size = (2,2),\n","                       strides = 2,\n","                         padding = 'valid')(output)\n","    output = keras.layers.BatchNormalization()(output)\n","\n","    #conv2_x pooling\n","    output = keras.layers.MaxPooling2D(pool_size = (2,2),\n","                                      strides = 2,)(output)\n","    # config list들의 길이만큼 반복해서 블록을 생성합니다.\n","    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n","        output = build_resnet_block(\n","            output,\n","            num_cnn=num_cnn,\n","            channel=channel,\n","            block_num=i\n","        )\n","    output = keras.layers.AveragePooling2D(padding = 'same')(output)\n","    output = keras.layers.Flatten(name='flatten')(output)\n","    output = keras.layers.Dense(512, activation='relu', name='fc1')(output)\n","    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\n","\n","    model = keras.Model(\n","        inputs=input_layer,\n","        outputs=output\n","    )\n","    return model"],"metadata":{"id":"kd9iDOKeqhiq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resnet_34 = build_resnet(is_50 = False)\n","resnet_50 = build_resnet(is_50 = True)\n","plain_resnet_34 = build_resnet(is_50 = False, is_plain = True)\n","plain_resnet_50 = build_resnet(is_50 = True, is_plain = True)"],"metadata":{"id":"6PpnrtKIqmWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resnet_34.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=tf.keras.optimizers.SGD(lr=0.01, clipnorm=1.),\n","    metrics=['accuracy'],\n",")\n","\n","history_34 = resnet_34.fit(train_input, train_target, epochs=50,\n","                    validation_data=(test_input, test_target))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":438},"id":"G3egFqJ2qoOi","executionInfo":{"status":"error","timestamp":1666077301429,"user_tz":-540,"elapsed":1383309,"user":{"displayName":"지나가는사람","userId":"14104558034696293435"}},"outputId":"ebcc64cd-2021-4380-f933-70f33f54a6c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","1563/1563 [==============================] - 3594s 2s/step - loss: 1.7498 - accuracy: 0.3863 - val_loss: 1.5241 - val_accuracy: 0.4612\n","Epoch 2/50\n"," 421/1563 [=======>......................] - ETA: 42:53 - loss: 1.4118 - accuracy: 0.4949"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-7aed4694e56e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m history_34 = resnet_34.fit(train_input, train_target, epochs=50,\n\u001b[0;32m----> 8\u001b[0;31m                     validation_data=(test_input, test_target))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}